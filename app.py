import cv2
import os
import time
import numpy as np
from flask import Flask, render_template, Response, request, jsonify
from ultralytics import YOLO

app = Flask(__name__)

# --- C·∫§U H√åNH ---
VIOLATION_DIR = "static/violations"
if not os.path.exists(VIOLATION_DIR):
    os.makedirs(VIOLATION_DIR)

# 1. Load Model chu·∫©n ƒë·ªÉ t√¨m XE M√ÅY (Class ID 3 trong COCO l√† Motorcycle)
print("Dang tai model nhan dien Xe...")
vehicle_model = YOLO("yolov8n.pt") 

# 2. Load Model ph√°t hi·ªán m≈© b·∫£o hi·ªÉm
# Model classes: 0='Hardhat' (co mu), 1='NO-Hardhat' (khong mu)
print("Dang tai model nhan dien Mu bao hiem...")
helmet_model = YOLO("best.pt")

# C·∫•u h√¨nh Camera (USB Webcam) - M·∫∑c ƒë·ªãnh camera 0
current_camera = 0
cap = None

def init_camera(camera_index):
    global cap
    try:
        if cap is not None:
            cap.release()
            time.sleep(0.5)  # Cho camera th·ªùi gian ƒë√≥ng
        cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)  # Windows DirectShow
        
        # ƒê·ª£i camera kh·ªüi ƒë·ªông
        time.sleep(1)
        
        if cap.isOpened():
            # Gi·∫£m ƒë·ªô ph√¢n gi·∫£i xu·ªëng HD ƒë·ªÉ m√°y Pentium ch·∫°y m∆∞·ª£t h∆°n
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Gi·∫£m buffer ƒë·ªÉ tr√°nh lag
            
            # ƒê·ªçc th·ª≠ m·ªôt v√†i frame ƒë·ªÉ camera ·ªïn ƒë·ªãnh
            for _ in range(5):
                cap.read()
            
            print(f"Camera {camera_index} khoi tao thanh cong!")
            return True
        else:
            print(f"Khong the mo camera {camera_index}")
            return False
    except Exception as e:
        print(f"Loi khi khoi tao camera {camera_index}: {e}")
        return False

# Kh·ªüi t·∫°o camera m·∫∑c ƒë·ªãnh
print("Khoi tao camera...")
if not init_camera(current_camera):
    print("CANH BAO: Khong the khoi tao camera mac dinh!")

last_save_time = 0
SAVE_COOLDOWN = 3  # Gi√¢y

# H√†m ki·ªÉm tra va ch·∫°m (Ki·ªÉm tra ng∆∞·ªùi c√≥ ng·ªìi tr√™n xe kh√¥ng)
def is_overlapping(box1, box2):
    # box: [x1, y1, x2, y2]
    x_left = max(box1[0], box2[0])
    y_top = max(box1[1], box2[1])
    x_right = min(box1[2], box2[2])
    y_bottom = min(box1[3], box2[3])

    if x_right < x_left or y_bottom < y_top:
        return False
    return True

def detect_and_process():
    global last_save_time
    frame_count = 0
    
    while True:
        if cap is None or not cap.isOpened():
            # N·∫øu camera kh√¥ng m·ªü ƒë∆∞·ª£c, tr·∫£ v·ªÅ frame tr·∫Øng v·ªõi th√¥ng b√°o
            blank_frame = 255 * np.ones((480, 640, 3), dtype=np.uint8)
            cv2.putText(blank_frame, "CAMERA KHONG KET NOI", (100, 240), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            ret, buffer = cv2.imencode('.jpg', blank_frame)
            yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            time.sleep(0.1)
            continue
            
        success, frame = cap.read()
        if not success:
            time.sleep(0.1)
            continue
        
        frame_count += 1
        # Ch·ªâ x·ª≠ l√Ω m·ªói 3 frame m·ªôt l·∫ßn ƒë·ªÉ gi·∫£m t·∫£i cho CPU y·∫øu
        if frame_count % 3 != 0:
            # V·∫´n m√£ h√≥a frame ƒë·ªÉ video m∆∞·ª£t, nh∆∞ng kh√¥ng ch·∫°y AI
            ret, buffer = cv2.imencode('.jpg', frame)
            yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            continue

        # --- B∆Ø·ªöC 1: T√¨m Xe M√°y (Class 3) ---
        # classes=[3] nghƒ©a l√† ch·ªâ t√¨m Motorcycle. B·ªè qua xe ƒë·∫°p (1) v√† ng∆∞·ªùi ƒëi b·ªô.
        vehicle_results = vehicle_model(frame, classes=[3], conf=0.3, imgsz=320, verbose=False)
        
        motorcycles = []
        for box in vehicle_results[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            motorcycles.append([x1, y1, x2, y2])
            # V·∫Ω khung xe m√°y m√†u Cam
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 165, 255), 2)
            cv2.putText(frame, "Xe May", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 2)

        # --- B∆Ø·ªöC 2: N·∫øu c√≥ Xe M√°y -> T√¨m ng∆∞·ªùi kh√¥ng n√≥n ---
        violation_confirmed = False
        
        if len(motorcycles) > 0:
            # T√¨m ng∆∞·ªùi KH√îNG ƒë·ªôi m≈© (class 1 = NO-Hardhat)
            helmet_results = helmet_model(frame, classes=[1], conf=0.3, imgsz=320, verbose=False)
            
            for box in helmet_results[0].boxes:
                hx1, hy1, hx2, hy2 = map(int, box.xyxy[0])
                cls_id = int(box.cls[0])
                class_name = helmet_model.names[cls_id]
                
                # Ki·ªÉm tra class vi ph·∫°m: NO-Hardhat (kh√¥ng m≈©)
                is_violation_class = (class_name in ['NO-Hardhat', 'NO-Hardhat', 'no-helmet', 'without-helmet'])
                
                if is_violation_class:
                    # --- B∆Ø·ªöC 3: Logic k·∫øt h·ª£p ---
                    # Ki·ªÉm tra xem c√°i ƒë·∫ßu n√†y c√≥ n·∫±m g·∫ßn chi·∫øc xe m√°y n√†o kh√¥ng
                    person_on_bike = False
                    for moto_box in motorcycles:
                        # M·ªü r·ªông v√πng ki·ªÉm tra xe m√°y l√™n tr√™n m·ªôt ch√∫t (v√¨ ƒë·∫ßu ng∆∞·ªùi ·ªü tr√™n xe)
                        expanded_moto = [moto_box[0], moto_box[1] - 100, moto_box[2], moto_box[3]]
                        
                        if is_overlapping([hx1, hy1, hx2, hy2], expanded_moto):
                            person_on_bike = True
                            break
                    
                    if person_on_bike:
                        color = (0, 0, 255) # ƒê·ªè (Vi ph·∫°m th·∫≠t s·ª±)
                        label = "VI PHAM"
                        violation_confirmed = True
                        # V·∫Ω khung ƒë·ªè quanh ƒë·∫ßu
                        cv2.rectangle(frame, (hx1, hy1), (hx2, hy2), color, 2)
                        cv2.putText(frame, label, (hx1, hy1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                    else:
                        # Ng∆∞·ªùi ƒëi b·ªô kh√¥ng ƒë·ªôi n√≥n -> B·ªè qua (V·∫Ω m√†u x√°m ho·∫∑c kh√¥ng v·∫Ω)
                        pass

        # --- B∆Ø·ªöC 4: L∆∞u ·∫£nh to√†n c·∫£nh ---
        if violation_confirmed:
            current_time = time.time()
            if current_time - last_save_time > SAVE_COOLDOWN:
                filename = f"violation_{int(current_time)}.jpg"
                filepath = os.path.join(VIOLATION_DIR, filename)
                # L∆∞u nguy√™n khung h√¨nh (To√†n c·∫£nh)
                cv2.imwrite(filepath, frame)
                print(f"üì∏ ƒê√£ ch·ª•p vi ph·∫°m xe m√°y: {filename}")
                last_save_time = current_time

        ret, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.route('/')
def index():
    try:
        images = sorted(os.listdir(VIOLATION_DIR), key=lambda x: os.path.getmtime(os.path.join(VIOLATION_DIR, x)), reverse=True)[:10]
    except:
        images = []
    return render_template('index.html', images=images, current_camera=current_camera)

@app.route('/debug')
def debug():
    """Trang debug ƒë·ªÉ ki·ªÉm tra h·ªá th·ªëng"""
    return render_template('debug.html')

@app.route('/video_feed')
def video_feed():
    return Response(detect_and_process(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/get_available_cameras')
def get_available_cameras():
    """L·∫•y danh s√°ch camera c√≥ s·∫µn"""
    available_cameras = []
    for i in range(5):  # Ki·ªÉm tra t·ªëi ƒëa 5 camera (gi·∫£m ƒë·ªÉ tr√°nh lag)
        if i == current_camera:
            # Camera ƒëang d√πng - kh√¥ng test l·∫°i
            available_cameras.append({
                'index': i,
                'name': f'Camera {i} (ƒêang d√πng)'
            })
            continue
        try:
            test_cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            if test_cap.isOpened():
                available_cameras.append({
                    'index': i,
                    'name': f'Camera {i}'
                })
                test_cap.release()
                time.sleep(0.2)  # Ch·ªù camera gi·∫£i ph√≥ng
        except:
            pass
    return jsonify(available_cameras)

@app.route('/change_camera', methods=['POST'])
def change_camera():
    """ƒê·ªïi camera"""
    global current_camera
    data = request.get_json()
    camera_index = int(data.get('camera_index', 0))
    
    if init_camera(camera_index):
        current_camera = camera_index
        return jsonify({'success': True, 'message': f'ƒê√£ chuy·ªÉn sang Camera {camera_index}'})
    else:
        return jsonify({'success': False, 'message': 'Kh√¥ng th·ªÉ m·ªü camera n√†y'}), 400

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
